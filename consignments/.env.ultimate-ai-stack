# ============================================================================
# ULTIMATE AI STACK - MULTI-PROVIDER CONFIGURATION
# ============================================================================
# Copy this to .env and configure your providers
# You can enable ALL providers or just the ones you need
# ============================================================================

# ----------------------------------------------------------------------------
# UNIVERSAL AI ROUTER SETTINGS
# ----------------------------------------------------------------------------
AI_ROUTER_AUTO_SELECT=true              # Auto-pick best provider per task
AI_ROUTER_ENABLE_FALLBACK=true          # Try next provider if one fails
AI_ROUTER_ENABLE_LOAD_BALANCING=true    # Distribute load across providers
AI_ROUTER_MAX_RETRIES=3                 # Max attempts across all providers

# Provider selection priorities (0-1, must sum to 1.0)
AI_ROUTER_COST_PRIORITY=0.3            # Higher = prioritize cost savings
AI_ROUTER_SPEED_PRIORITY=0.4           # Higher = prioritize speed
AI_ROUTER_QUALITY_PRIORITY=0.3         # Higher = prioritize quality

# Cost controls
AI_MONTHLY_BUDGET_USD=500              # Monthly spending limit (all providers)
AI_COST_ALERT_THRESHOLD=0.8            # Alert when 80% of budget used

# ----------------------------------------------------------------------------
# OPENAI (GPT-4o, GPT-4, GPT-3.5-turbo)
# ----------------------------------------------------------------------------
OPENAI_ENABLED=true
OPENAI_API_KEY=sk-proj-your-openai-api-key-here
OPENAI_MODEL=gpt-4o                    # Options: gpt-4o, gpt-4, gpt-3.5-turbo
OPENAI_ENDPOINT=https://api.openai.com/v1

# Model-specific settings
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000
OPENAI_TIMEOUT=30

# ----------------------------------------------------------------------------
# ANTHROPIC (Claude 3.5 Sonnet, Opus)
# ----------------------------------------------------------------------------
ANTHROPIC_ENABLED=true
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022    # Options: claude-3-5-sonnet-20241022, claude-3-opus-20240229
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1

# Model-specific settings
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TIMEOUT=60                   # Claude can be slower but more thorough

# ----------------------------------------------------------------------------
# INTELLIGENCE HUB (Internal AI Platform at gpt.ecigdis.co.nz)
# ✅ CONFIGURED WITH REAL MCP SERVER v3.0.0 ENDPOINTS
# ----------------------------------------------------------------------------
INTELLIGENCE_HUB_ENABLED=true
INTELLIGENCE_HUB_API_KEY=31ce0106609a6c5bc4f7ece0deb2f764df90a06167bda83468883516302a6a35

# MCP Server v3 Endpoints (JSON-RPC)
INTELLIGENCE_HUB_MCP_ENDPOINT=https://gpt.ecigdis.co.nz/mcp/server_v3.php
INTELLIGENCE_HUB_CHAT_ENDPOINT=https://gpt.ecigdis.co.nz/api/v1/chat/completions

# Additional endpoints
INTELLIGENCE_HUB_HEALTH_ENDPOINT=https://gpt.ecigdis.co.nz/mcp/server_v3.php?action=health
INTELLIGENCE_HUB_META_ENDPOINT=https://gpt.ecigdis.co.nz/mcp/server_v3.php?action=meta
INTELLIGENCE_HUB_CONVERSATION_ENDPOINT=https://gpt.ecigdis.co.nz/api/save_conversation.php

# Intelligence Hub features (8,645 indexed files!)
INTELLIGENCE_HUB_USE_RAG=true          # Use RAG (Retrieval-Augmented Generation)
INTELLIGENCE_HUB_USE_MCP=true          # Use MCP Server tools (55+ tools available!)
INTELLIGENCE_HUB_AUTO_RECORD=true      # Automatically record all conversations
INTELLIGENCE_HUB_TIMEOUT=60

# ----------------------------------------------------------------------------
# CLAUDE BOT (Custom Claude Instance)
# ----------------------------------------------------------------------------
CLAUDE_BOT_ENABLED=false               # Set to true when you configure your Claude Bot
CLAUDE_BOT_API_KEY=                    # Your Claude Bot API key
CLAUDE_BOT_ENDPOINT=                   # Your Claude Bot endpoint URL
CLAUDE_BOT_MODEL=claude-3-5-sonnet-20241022

# Claude Bot settings
CLAUDE_BOT_TEMPERATURE=0.7
CLAUDE_BOT_MAX_TOKENS=4096
CLAUDE_BOT_TIMEOUT=60

# ----------------------------------------------------------------------------
# CACHING & PERFORMANCE
# ----------------------------------------------------------------------------
AI_CACHE_ENABLED=true                  # Cache AI responses
AI_CACHE_TTL=900                       # Cache duration (seconds, 15 min default)
AI_CACHE_MAX_SIZE=1000                 # Max cached responses

# ----------------------------------------------------------------------------
# LOGGING & MONITORING
# ----------------------------------------------------------------------------
AI_LOG_ALL_REQUESTS=true               # Log every AI request
AI_LOG_COSTS=true                      # Track costs per request
AI_LOG_PERFORMANCE=true                # Track response times
AI_LOG_LEVEL=info                      # debug, info, warning, error

# ----------------------------------------------------------------------------
# FEATURES
# ----------------------------------------------------------------------------
AI_ENABLE_FUNCTION_CALLING=true        # Allow AI to trigger actions
AI_ENABLE_CONVERSATIONS=true           # Track conversation history
AI_ENABLE_FEEDBACK=true                # Collect user feedback
AI_ENABLE_LEARNING=true                # Learn from feedback

# ----------------------------------------------------------------------------
# RATE LIMITING (per provider, per minute)
# ----------------------------------------------------------------------------
AI_RATE_LIMIT_ENABLED=true
AI_RATE_LIMIT_OPENAI=60                # 60 requests/minute
AI_RATE_LIMIT_ANTHROPIC=50             # 50 requests/minute
AI_RATE_LIMIT_INTELLIGENCE_HUB=120     # 120 requests/minute (internal, higher limit)
AI_RATE_LIMIT_CLAUDE_BOT=60            # 60 requests/minute

# ----------------------------------------------------------------------------
# PROVIDER-SPECIFIC OPTIMIZATIONS
# ----------------------------------------------------------------------------

# OpenAI optimizations
OPENAI_USE_STREAMING=false             # Stream responses (for real-time chat)
OPENAI_FREQUENCY_PENALTY=0             # -2.0 to 2.0
OPENAI_PRESENCE_PENALTY=0              # -2.0 to 2.0

# Anthropic optimizations
ANTHROPIC_TOP_K=40                     # Top-k sampling
ANTHROPIC_TOP_P=0.9                    # Top-p (nucleus) sampling

# Intelligence Hub optimizations
INTELLIGENCE_HUB_PREFER_CACHE=true     # Prefer cached responses
INTELLIGENCE_HUB_ENABLE_WORKFLOWS=true # Enable workflow orchestration
INTELLIGENCE_HUB_ENABLE_FRONTEND=true  # Enable frontend automation

# ----------------------------------------------------------------------------
# TASK-SPECIFIC OVERRIDES
# ----------------------------------------------------------------------------
# Force specific providers for certain task types

AI_PROVIDER_QUICK=openai               # Quick queries → OpenAI (fast)
AI_PROVIDER_ANALYSIS=anthropic         # Deep analysis → Anthropic (thorough)
AI_PROVIDER_INTERNAL=intelligence_hub  # Internal context → Intelligence Hub (RAG)
AI_PROVIDER_CODE=openai                # Code generation → OpenAI (good at code)
AI_PROVIDER_CONVERSATIONAL=claude_bot  # Natural chat → Claude Bot

# ----------------------------------------------------------------------------
# DEVELOPMENT & TESTING
# ----------------------------------------------------------------------------
AI_DEBUG_MODE=false                    # Enable verbose debug output
AI_TEST_MODE=false                     # Use test endpoints (no real API calls)
AI_MOCK_RESPONSES=false                # Return mock data instead of API calls

# ----------------------------------------------------------------------------
# SECURITY
# ----------------------------------------------------------------------------
AI_REDACT_PII=true                     # Remove PII from logs
AI_ENCRYPT_CACHE=false                 # Encrypt cached responses (requires encryption key)
AI_REQUIRE_AUTH=true                   # Require user authentication for AI features

# ----------------------------------------------------------------------------
# COST OPTIMIZATION
# ----------------------------------------------------------------------------
AI_PREFER_CHEAPER_MODELS=true          # Prefer GPT-3.5 over GPT-4 when quality isn't critical
AI_BATCH_REQUESTS=true                 # Batch multiple requests when possible
AI_COMPRESS_CONTEXT=true               # Compress context to reduce tokens

# ----------------------------------------------------------------------------
# EMERGENCY CONTROLS
# ----------------------------------------------------------------------------
AI_KILL_SWITCH=false                   # Emergency disable ALL AI features
AI_DISABLE_OPENAI=false                # Emergency disable OpenAI
AI_DISABLE_ANTHROPIC=false             # Emergency disable Anthropic
AI_DISABLE_INTELLIGENCE_HUB=false      # Emergency disable Intelligence Hub
AI_DISABLE_CLAUDE_BOT=false            # Emergency disable Claude Bot
